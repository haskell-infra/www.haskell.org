<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2 Final//EN">
<HTML>
<HEAD>
<TITLE>Happy User Guide: Tips</TITLE>
</HEAD>
<BODY>
Next
<A HREF="happy-5.html">Previous</A>
<A HREF="happy.html#toc6">Contents</A>
<HR>
<H2><A NAME="sec:tips"></A> <A NAME="s6">6. Tips</A></H2>

<P>
<P>This section contains a lot of accumulated lore about using Happy.
<P>
<H2><A NAME="sec:performance-tips"></A> <A NAME="ss6.1">6.1 Performance Tips</A>
</H2>

<P>
<P>How to make your parser go faster:
<P>
<UL>
<LI> If you are using ghc, generate parsers using the <CODE>-g</CODE>
option, and compile them using ghc with the <CODE>-fglasgow-exts</CODE>
option.  This is worth about 10-20%.
</LI>
<LI> The lexical analyser is usually the most performance critical
part of a parser, so it's worth spending some time optimising this.
Profiling tools are essential here.  In really dire circumstances,
resort to some of the hacks that are used in the Glasgow Haskell
Compiler's interface-file lexer.
</LI>
<LI> Simplify the grammar as much as possible, as this reduces the
number of states and reduction rules that need to be applied.
</LI>
<LI> Use left recursion rather than right recursion wherever possible.
While not strictly a performance issue, this affects the size of the
parser stack, which is kept on the heap and thus needs to be garbage
collected.
</LI>
</UL>
<P>
<P>
<H2><A NAME="sec:compilation-time"></A> <A NAME="ss6.2">6.2 Compilation-Time Tips</A>
</H2>

<P>
<P>We have found that compiling parsers generated by Happy can take a
large amount of time/memory, so here's some tips on making things more
sensible:
<P>
<UL>
<LI> Include as little code as possible in the module trailer.  This
code is included verbatim in the generated parser, so if any of it can
go in a separate module, do so.
</LI>
<LI> Give type signatures for everything.  This is reported to improve
things by about 50%.  If there is a type signature for every single
non-terminal in the grammar, then Happy automatically generates type
signatures for most functions in the parser.
</LI>
<LI> Simplify the grammar as much as possible (applies to
everything, this one).
</LI>
<LI> GHC versions from around 2.06 onwards are reputedly better at
compiling Happy-generated parsers.
</LI>
</UL>
<P>
<H2><A NAME="sec:finding-errors"></A> <A NAME="ss6.3">6.3 Finding Type Errors</A>
</H2>

<P>
<P>Finding type errors in grammar files is inherently difficult because
the code for reductions is moved around before being placed in the
parser.  We currently have no way of passing the original filename and
line numbers to the Haskell compiler, so there is no alternative but
to look at the parser and match the code to the grammar file.  An info
file (generated by the <CODE>-i</CODE> option) can be helpful here.
<P>Type signature sometimes help by pinning down the particular error to
the place where the mistake is made, not half way down the file.  For
each production in the grammar, there's a bit of code in the generated
file that looks like this:
<P>
<BLOCKQUOTE><CODE>
<PRE>
HappyAbsSyn&lt;n> ( E )
</PRE>
</CODE></BLOCKQUOTE>
<P>where <CODE>E</CODE> is the Haskell expression from the grammar file (with
<CODE>$n</CODE> replaced by <CODE>happy_var_n</CODE>).  If there is a type
signature for this production, then Happy will have taken it into
account when declaring the HappyAbsSyn datatype, and errors in <CODE>E</CODE>
will be caught right here.  Of course, the error may be really caused
by incorrect use of one of the <CODE>happy_var_n</CODE> variables.
<P>(this section will contain more info as we gain experience with creating
grammar files.  Please send us any helpful tips you find.)
<P>
<H2><A NAME="sec:conflict-tips"></A> <A NAME="ss6.4">6.4 Conflict Tips</A>
</H2>

<P>
<P>Conflicts arise from ambiguities in the grammar.  That is, some input
sequences may possess more than one parse.  Shift/reduce conflicts are
benign in the sense that they are easily resolved (Happy automatically
selects the shift action, as this is usually the intended one).
Reduce/reduce conflicts are more serious.  A reduce/reduce conflict
implies that a certain sequence of tokens on the input can represent
more than one non-terminal, and the parser is uncertain as to which
reduction rule to use.  It will select the reduction rule uppermost in
the grammar file, so if you really must have a reduce/reduce conflict
you can select which rule will be used by putting it first in your
grammar file.
<P>It is usually possible to remove conflicts from the grammar, but
sometimes this is at the expense of clarity and simplicity.  Here is a
cut-down example from the grammar of Haskell (1.2):
<P>
<BLOCKQUOTE><CODE>
<PRE>
exp     : exp op exp0
        | exp0

exp0    : if exp then exp else exp
        ...
        | atom

atom    : var
        | integer
        | '(' exp ')'
        ...
</PRE>
</CODE></BLOCKQUOTE>
<P>This grammar has a shift/reduce conflict, due to the following
ambiguity.  In an input such as
<P>
<BLOCKQUOTE><CODE>
<PRE>
if 1 then 2 else 3 + 4
</PRE>
</CODE></BLOCKQUOTE>
<P>the grammar doesn't specify whether the parse should be
<P>
<BLOCKQUOTE><CODE>
<PRE>
if 1 then 2 else (3 + 4)
</PRE>
</CODE></BLOCKQUOTE>
<P>or
<P>
<BLOCKQUOTE><CODE>
<PRE>
(if 1 then 2 else 3) + 4
</PRE>
</CODE></BLOCKQUOTE>
<P>and the ambiguity shows up as a shift/reduce conflict on reading the
'op' symbol.  In this case, the first parse is the intended one (the
'longest parse' rule), which corresponds to the shift action.
Removing this conflict relies on noticing that the expression on the
left-hand side of an infix operator can't be an <CODE>exp0</CODE> (the grammar
previously said otherwise, but since the conflict was resolved as
shift, this parse was not allowed).  We can reformulate the <CODE>exp</CODE>
rule as:
<P>
<BLOCKQUOTE><CODE>
<PRE>
exp     : atom op exp
        | exp0
</PRE>
</CODE></BLOCKQUOTE>
<P>and this removes the conflict, but at the expense of some stack space
while parsing (we turned a left-recursion into a right-recursion).
There are alternatives using left-recursion, but they all involve adding
extra states to the parser, so most programmers will prefer to keep the
conflict in favour of a clearer and more efficient parser.
<P>
<H3><A NAME="sec:lalr"></A> LALR(1) parsers</H3>

<P>
<P>There are three basic ways to build a shift-reduce parser.  Full LR(1)
(the `L' is the direction in which the input is scanned, the `R' is the
way in which the parse is built, and the `1' is the number of tokens of
lookahead) generates a parser with many states, and is therefore large
and slow.  SLR(1) (simple LR(1)) is a cut-down version of LR(1) which
generates parsers with roughly one-tenth as many states, but lacks the
power to parse many grammars (it finds conflicts in grammars which have
none under LR(1)). 
<P>LALR(1) (look-ahead LR(1)), the method used by Happy and <CODE>yacc</CODE>, is
tradeoff between the two.  An LALR(1) parser has the same number of
states as an SLR(1) parser, but it uses a more complex method to
calculate the lookahead tokens that are valid at each point, and
resolves many of the conflicts that SLR(1) finds.  However, there may
still be conflicts in an LALR(1) parser that wouldn't be there with
full LR(1).
<P>
<HR>
Next
<A HREF="happy-5.html">Previous</A>
<A HREF="happy.html#toc6">Contents</A>
</BODY>
</HTML>
